{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamburg Birds Classifier\n",
    "\n",
    "This notebook is training the classifier for some of the bird spieces which can be found in Hamburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fastbook\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_types = [\n",
    "    'European Robin',\n",
    "    'Marsh Tit',\n",
    "    'Eurasian Blackbird',\n",
    "    'Eurasian Nuthatch',\n",
    "    'Eurasian Jay',\n",
    "    'Eurasian Wren',\n",
    "    'Hawfinch',\n",
    "    'Bullfinch',\n",
    "    'Common Starling',\n",
    "    'Greylag Goose',\n",
    "    'Barnacle Goose',\n",
    "    'Meadow Pipit',\n",
    "    'Common Wood Pigeon',\n",
    "    'Mistle Thrush'\n",
    "]\n",
    "path = Path('birds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for bird in birds_types:\n",
    "        dest = (path/bird)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, bird)\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = fns = get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdsDB = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=1337),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = birdsDB.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=36, nrows=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wil do a few iterations of training the model and removing incorrect data. This will improve the quality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = birdsDB.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=[accuracy, error_rate], cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(7, nrows=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ImageClassifierCleaner(learn50, height=256, width=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in cleaner.delete():\n",
    "        cleaner.fns[idx].unlink()\n",
    "\n",
    "for idx,cat in cleaner.change():\n",
    "        shutil.move(str(cleaner.fns[idx]), path/cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After we polished the dataset, let's start the batch size data collection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to check the batch size effects on two 3 architectures: ResNet50, ResNet34 and ResNet18. Unfortunately Resnet101 was too big for my GPU to swallow and it is not the part of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = {\n",
    "    \"rn50\": resnet50,\n",
    "    \"rn34\": resnet34,\n",
    "    \"rn18\": resnet18,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function which we use to get the training restuls. CSVLogger is what we need to have the training metrics saved in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, batch_size, index):\n",
    "    dls = birdsDB.dataloaders(path, bs=batch_size)\n",
    "    learn = cnn_learner(dls, architectures[arch], metrics=error_rate, cbs=[ShowGraphCallback, CSVLogger(fname=f'birds-{arch}-bs{batch_size}-{index}.csv')]).to_fp16()\n",
    "    learn.fine_tune(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final training loop. It took around 6 hours to complete using nvidia rtx 2080ti GPU, so have a bit of patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in ['rn50', 'rn34', 'rn18']:\n",
    "    for bs in [128, 64, 32, 16, 8, 4]:\n",
    "        for index in range(10):\n",
    "            train(arch, bs, index)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
